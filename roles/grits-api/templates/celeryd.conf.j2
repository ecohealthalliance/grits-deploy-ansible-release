; ==================================
;  based on this example: https://github.com/celery/celery/blob/3.1/extra/supervisord/celeryd.conf
; ==================================
; This worker should be reserved for diagnoses that need to happen right away,
; rather than for batch jobs that will take a long time to complete.
; The other workers will also handle priority diagnoses if they are not
; performing a batch job
[program:celery_priority]
command={{ grits_env }}/bin/celery worker -A tasks -Q priority --loglevel=INFO --concurrency={{ celery_priority_workers }}
directory={{ grits_api_prefix }}
user={{ grits_user }}
environment=NLTK_DATA=/home/{{ grits_user }}/nltk_data
autostart=true
autorestart=true
startsecs=10

; Need to wait for currently executing tasks to finish at shutdown.
; Increase this if you have very long running tasks.
stopwaitsecs = 600

; When resorting to send SIGKILL to the program to terminate it
; send SIGKILL to its whole process group instead,
; taking care of its children as well.
killasgroup=true

; Use different workers for batch jobs so they don't block user submissions.
; I threads to scrape and preprocess because most the time is spent making http
; so a single process provides a sufficinet amount of cpu time.
[program:celery_process]
command={{ grits_env }}/bin/celery worker -A tasks -Q process -P threads --concurrency 10 --loglevel=INFO
directory={{ grits_api_prefix }}
user={{ grits_user }}
environment=NLTK_DATA=/home/{{ grits_user }}/nltk_data
autostart=true
autorestart=true
startsecs=10
stopwaitsecs=600
killasgroup=true

[program:celery_diagnose]
command={{ grits_env }}/bin/celery worker -A tasks -Q diagnose,priority --loglevel=INFO --concurrency={{ celery_batch_workers }}
directory={{ grits_api_prefix }}
user={{ grits_user }}
environment=NLTK_DATA=/home/{{ grits_user }}/nltk_data
autostart=true
autorestart=true
startsecs=10
stopwaitsecs=600
killasgroup=true
